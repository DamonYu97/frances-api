{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF-   NLS - \n",
    "\n",
    "This notebook is going to create the RDF triples to generate our RDLIB GRAPH\n",
    "\n",
    "Before we need to run **Metadata_Pages_NLS.ipynb** to get the **collection dataframe**. \n",
    "\n",
    "The collection dataframes will have this shape:\n",
    "\n",
    "\n",
    "- MMSID                                                   9937033633804341\n",
    "- serieTitle                            Chapbooks printed in Scotland\n",
    "- editor                                                       Milne, John\n",
    "- editor_date                                                    1792-1871\n",
    "- genre                              Chapbooks-Scotland-Aberdeen-1801-1900\n",
    "- language                                                             eng\n",
    "- metsXML                                               104184105-mets.xml\n",
    "- termsOfAddress                                                      None\n",
    "- numberOfPages                                                          8\n",
    "- numberOfWords                                                         53\n",
    "- permanentURL                            https://digital.nls.uk/104184105\n",
    "- physicalDescription                                        8 p. ; 18 cm.\n",
    "- place                                                           Aberdeen\n",
    "- publisher                             Printed by A. Imlay, 22, Long Acre\n",
    "- referencedBy                                                        None\n",
    "- shelfLocator                                               L.C.2786.A(1)\n",
    "- altoXML                                  104184105/alto/107134030.34.xml\n",
    "- serieSubTitle                             to the tune of Johnny Cop\n",
    "- text                   A SONG JRAISB OP THE ^ HIGHLAND LADS. To the T...\n",
    "- pageNum                                                            Page1\n",
    "- volumeTitle                          song in praise of the highland lads\n",
    "- volumeId                                                       104184105\n",
    "- year                                                                1826\n",
    "- collectionNum                                                          0\n",
    "- part                                                                   0\n",
    "- publisherPersons                                                      []\n",
    "- numberOfVolumes                                                     3080\n",
    "- volumeNum                                                             1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import collections\n",
    "import string\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yaml import safe_load\n",
    "from pandas.io.json import json_normalize\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_AZ_REGEXP = re.compile('[^a-zA-Z]')\n",
    "NON_AZ_19_REGEXP = re.compile('[^a-z0-9]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serie2rdf(data, g, nls):\n",
    "\n",
    "    serie = URIRef(\"https://w3id.org/nls/i/Serie/\"+str(data[\"MMSID\"]))\n",
    "    serie_title= data[\"serieTitle\"]+\",\" +str(data[\"year\"])\n",
    "    g.add((serie, RDF.type, nls.Serie))\n",
    "    g.add((serie, nls.number, Literal(data[\"serieNum\"], datatype=XSD.integer)))\n",
    "    g.add((serie, nls.title, Literal(serie_title, datatype=XSD.string)))\n",
    "    g.add((serie, nls.subtitle, Literal(data[\"serieSubTitle\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.publicationYear, Literal(data[\"year\"], datatype=XSD.integer)))\n",
    "    g.add((serie, nls.printedAt, Literal(data[\"place\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.mmsid, Literal(str(data[\"MMSID\"]), datatype=XSD.string)))\n",
    "    g.add((serie, nls.physicalDescription, Literal(data[\"physicalDescription\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.genre, Literal(data[\"genre\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.language, Literal(data[\"language\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.shelfLocator, Literal(data[\"shelfLocator\"], datatype=XSD.string)))\n",
    "    g.add((serie, nls.numberOfVolumes, Literal(data[\"numberOfVolumes\"], datatype=XSD.integer)))\n",
    "\n",
    "    #### Editor \n",
    "    \n",
    "\n",
    "    if data[\"editor\"]!=0:\n",
    "        name=data[\"editor\"].replace(\" \", \"\")\n",
    "        name=name.replace(\"]\", \"\")\n",
    "        name=name.replace(\",\", \"\")\n",
    "        name=name.replace(\".\", \"\")\n",
    "        name=name.replace(\":-\", \"\")\n",
    "        name=re.sub(NON_AZ_REGEXP, '', name)\n",
    "        \n",
    "        \n",
    "        editor = URIRef(\"https://w3id.org/nls/i/Person/\"+str(name))\n",
    "        g.add((editor, RDF.type, nls.Person))\n",
    "        g.add((editor, nls.name, Literal(data[\"editor\"], datatype=XSD.string)))\n",
    "\n",
    "        try:\n",
    "            if data[\"editor_date\"]!=0:\n",
    "                tmpDate=data[\"editor_date\"].split(\"-\")\n",
    "                \n",
    "                if \"?\" in tmpDate[0]:\n",
    "                    tmpDate[0]=tmpDate[0].replace(\"?\", \"\")\n",
    "                if \"?\" in tmpDate[1]:\n",
    "                    tmpDate[1]=tmpDate[1].replace(\"?\", \"\")\n",
    "                \n",
    "                birthDate=datetime.strptime(tmpDate[0], '%Y')\n",
    "                deathDate=datetime.strptime(tmpDate[1], '%Y')\n",
    "                g.add((editor, nls.birthDate, Literal(birthDate, datatype=XSD.dateTime)))\n",
    "                g.add((editor, nls.deathDate, Literal(deathDate, datatype=XSD.dateTime)))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        if data[\"termsOfAddress\"] != 0:\n",
    "            g.add((editor, nls.termsOfAddress, Literal(data[\"termsOfAddress\"], datatype=XSD.string)))\n",
    "\n",
    "        g.add((serie, nls.editor, editor))\n",
    "\n",
    "    #### Publishers Persons \n",
    "\n",
    "    #This was the result to pass entity recognition to publisher\n",
    "\n",
    "    if data[\"publisherPersons\"] != 0:\n",
    "        publisherPersons=name=data[\"publisherPersons\"]\n",
    "        for p in publisherPersons: \n",
    "            name=p.replace(\" \", \"\")\n",
    "            name=name.replace(\"]\", \"\")\n",
    "            name=name.replace(\",\", \"_\")\n",
    "            name=name.replace(\".\", \"\")\n",
    "            name=name.replace(\":-\", \"\")\n",
    "            name=re.sub(NON_AZ_REGEXP, '', name)\n",
    "            publisher = URIRef(\"https://w3id.org/nls/i/Person/\"+name)\n",
    "            #print(\"---- Publisher %s\" %publisher)\n",
    "            #if \"RobertDrummond\" in name:\n",
    "            #    print(\"------ WARNING!!! %s\" %name)\n",
    "            g.add((publisher, RDF.type, nls.Person))\n",
    "            g.add((publisher, nls.name, Literal(p, datatype=XSD.string)))\n",
    "            g.add((serie, nls.publisher, publisher))\n",
    "        \n",
    "    #### Is Referenced by  \n",
    "\n",
    "    if data[\"referencedBy\"] != 0:\n",
    "        references=data[\"referencedBy\"]\n",
    "        for r in references: \n",
    "            name=r.replace(\" \", \"\")\n",
    "            book = URIRef(\"https://w3id.org/nls/i/Book/\"+name)\n",
    "            g.add((book, RDF.type, nls.Book))\n",
    "            g.add((book, nls.title, Literal(r, datatype=XSD.string)))\n",
    "            g.add((serie, nls.referencedBy, book))\n",
    "            \n",
    "    return g, serie\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_json('results/chapbooks_dataframe', orient=\"index\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_json('results/ladiesDebating_dataframe', orient=\"index\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMSID                                                   9938524913804340\n",
       "edition                                                         Volume 2\n",
       "editor                               Edinburgh Essay Society (Edinburgh)\n",
       "editor_date                                                          0.0\n",
       "genre                                                         periodical\n",
       "language                                                             eng\n",
       "metsXML                                               103655648-mets.xml\n",
       "termsOfAddress                                                       0.0\n",
       "numberOfPages                                                        316\n",
       "numberOfWords                                                          1\n",
       "permanentURL                            https://digital.nls.uk/103655648\n",
       "physicalDescription    10 v. ([2], 286; [2], iv, 292; [2], iv, 286; [...\n",
       "place                                                          Edinburgh\n",
       "publisher                                                              0\n",
       "referencedBy                                                         0.0\n",
       "shelfLocator                                                       U.431\n",
       "altoXML                                  103655648/alto/104346954.34.xml\n",
       "serieSubTitle                                                        0.0\n",
       "text                                                             UL.u^\\,\n",
       "pageNum                                                                4\n",
       "volumeTitle                        attempt. A literary magazine Volume 2\n",
       "volumeId                                                       103655648\n",
       "year                                                                1865\n",
       "serieNum                                                               0\n",
       "part                                                                   0\n",
       "serieTitle             Edinburgh Ladies’ Debating Society_attempt. A ...\n",
       "publisherPersons                                                       0\n",
       "numberOfVolumes                                                       10\n",
       "volumeNum                                                              2\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp[\"pageNum\"] = df['pageNum'].apply(lambda s:s.split('Page')[1])\n",
    "#df['pageNum']= tmp[\"pageNum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_MMSID=df[\"MMSID\"].unique()\n",
    "len(list_MMSID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Graph and import the information of the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace, XSD\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "\n",
    "# Create a Graph\n",
    "g = Graph()\n",
    "\n",
    "g.namespace_manager.bind('nls', Namespace(\"https://w3id.org/nls#\"), override=\"False\")\n",
    "nls = Namespace(\"https://w3id.org/nls#\")\n",
    "\n",
    "\n",
    "list_MMSID=df[\"MMSID\"].unique()\n",
    "for s in range(0, len(list_MMSID)):\n",
    "    \n",
    "    ### SERIE\n",
    "    #print(\"Serie: %s\" %list_MMSID[s])\n",
    "    \n",
    "    df_serie=df[df['MMSID'] == list_MMSID[s]].reset_index(drop=True)\n",
    "    serie_data = df_serie.loc[0]\n",
    "    g, serie = serie2rdf(serie_data,g, nls)\n",
    "    \n",
    "    ### VOLUMES \n",
    "    list_vols = df_serie[\"volumeNum\"].unique()\n",
    "    \n",
    "    for v in range(0,len(list_vols)):\n",
    "        \n",
    "        \n",
    "    #print(\"Vol %s\" % list_vols[v])\n",
    "        df_vl=df_serie[df_serie[\"volumeNum\"] == list_vols[v]].reset_index(drop=True)\n",
    "        volume_data=df_vl.loc[0]\n",
    "        volume_id=volume_data[\"volumeId\"]\n",
    "        volume = URIRef(\"https://w3id.org/nls/i/Volume/\"+str(volume_data[\"MMSID\"])+\"_\"+str(volume_data[\"volumeId\"]))\n",
    "        #print(volume)\n",
    "    \n",
    "        g.add((volume, RDF.type, nls.Volume))\n",
    "        g.add((volume, nls.volumeId, Literal(volume_data[\"volumeId\"], datatype=XSD.int)))\n",
    "        g.add((volume, nls.number, Literal(volume_data[\"volumeNum\"], datatype=XSD.int)))\n",
    "        g.add((volume, nls.title, Literal(volume_data[\"volumeTitle\"], datatype=XSD.string)))\n",
    "        if volume_data[\"part\"]!=0:\n",
    "            g.add((volume, nls.part, Literal(volume_data[\"part\"], datatype=XSD.string)))\n",
    "    \n",
    "        g.add((volume, nls.metsXML, Literal(volume_data[\"metsXML\"], datatype=XSD.string)))\n",
    "        g.add((volume, nls.permanentURL, Literal(volume_data[\"permanentURL\"], datatype=XSD.string)))\n",
    "        g.add((volume, nls.numberOfPages, Literal(volume_data[\"numberOfPages\"], datatype=XSD.string)))\n",
    "    \n",
    "        #print(\"Volume is %s\" % volume)\n",
    "        g.add((serie, nls.hasPart, volume))\n",
    "    \n",
    "        list_pages = df_vl[\"pageNum\"].unique()\n",
    "    \n",
    "                        \n",
    "        #### PAGES\n",
    "        for p in range(0, len(list_pages)):\n",
    "            df_p=df_vl[df_vl[\"pageNum\"] == list_pages[p]].reset_index(drop=True)\n",
    "            df_page=df_p.loc[0]\n",
    "            page= URIRef(\"https://w3id.org/nls/i/Page/\"+ str(df_page[\"MMSID\"])+\"_\"+str(df_page[\"volumeId\"])+\"_\"+str(df_page[\"pageNum\"]))\n",
    "            #print(\"Page is %s\" %page)\n",
    "        \n",
    "            g.add((page, RDF.type, nls.Page))\n",
    "            \n",
    "            #df_p=df_page[\"pageNum\"].split('Page')[0]\n",
    "            \n",
    "            g.add((page, nls.number, Literal(df_page[\"pageNum\"], datatype=XSD.int)))\n",
    "            g.add((page, nls.numberOfWords, Literal(df_page[\"numberOfWords\"], datatype=XSD.int)))\n",
    "            g.add((page, nls.text,  Literal(df_page[\"text\"], datatype=XSD.string)))\n",
    "            g.add((page, nls.altoXML, Literal(df_page[\"altoXML\"], datatype=XSD.string)))\n",
    "            g.add((volume, nls.hasPart, page))\n",
    "      \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N6256eb240772442aa8873fead581d7b0 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Graph in the RDF Turtle format\n",
    "#g.serialize(format=\"turtle\", destination=\"results/chapbooks_scotland.ttl\")\n",
    "g.serialize(format=\"turtle\", destination=\"results/ladiesDebating.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the elements that we have added for the last Edition added in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/nls/i/Serie/9927010233804340 http://www.w3.org/1999/02/22-rdf-syntax-ns#type https://w3id.org/nls#Serie\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#number 1\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#title Edinburgh Ladies’ Debating Society_Ladies' Edinburgh magazine,1875\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#subtitle 0.0\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#publicationYear 1875\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#printedAt Edinburgh\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#mmsid 9927010233804340\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#physicalDescription v. ; 21 cm.\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#genre periodical\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#language eng\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#shelfLocator U.393\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#numberOfVolumes 6\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655658\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655659\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655660\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655661\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655662\n",
      "https://w3id.org/nls/i/Serie/9927010233804340 https://w3id.org/nls#hasPart https://w3id.org/nls/i/Volume/9927010233804340_103655663\n"
     ]
    }
   ],
   "source": [
    "for s,p,o in g.triples((serie, None, None)):\n",
    "  print(s,p,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/nls/i/Serie/9938524913804340 https://w3id.org/nls#editor https://w3id.org/nls/i/Person/EdinburghEssaySocietyEdinburgh\n"
     ]
    }
   ],
   "source": [
    "for s,p,o in g.triples((None, nls.editor, None)):\n",
    "  print(s,p,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
