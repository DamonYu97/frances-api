{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging EB terms-  NLS -  Encyclopaedia Britannica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yaml import safe_load\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_query_results(filename):\n",
    "    with open('./results_NLS/'+filename, 'r') as f:\n",
    "        query_results = safe_load(f)\n",
    "    return query_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_results(filename, results):\n",
    "    with open('./results_NLS/'+filename, 'w') as f:\n",
    "        documents = yaml.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(query_results):\n",
    "  \n",
    "    \n",
    "    for edition in query_results:\n",
    "        for page in query_results[edition]:\n",
    "            #print(page[1].keys())\n",
    "            column_list=list(page[1].keys())\n",
    "            break\n",
    "        break\n",
    "        \n",
    "    data=[]\n",
    "    for edition in query_results:\n",
    "        for page in query_results[edition]:\n",
    "            try:\n",
    "                data.append(page[1])\n",
    "               \n",
    "            except:\n",
    "                pass\n",
    "    df = pd.DataFrame(data, columns = column_list)\n",
    "    #removing the columns that I dont need \n",
    "    df= df.drop(['last_term_in_page', 'model', 'num_articles', 'num_page_words', 'num_text_unit' , 'text_unit', 'type_archive'], axis=1)\n",
    "    #renaming the page num\n",
    "    df= df.rename(columns={\"text_unit_id\": \"page_num\", \"type_page\": \"type_article\"})\n",
    "    #removing 'Page' from the string\n",
    "    df[\"page_num\"] = df[\"page_num\"].str.replace(\"Page\", \"\")\n",
    "    df[\"page_num\"] = df[\"page_num\"].astype(int)\n",
    "    df_tmp= df[\"edition\"].str.split(\"Volume\", expand=True)[1].str.split(\",\", expand=True)\n",
    "    df[\"volume\"]= df_tmp[0]\n",
    "    df[\"letters\"] = df_tmp[1]\n",
    "    df['volume'] = df[\"volume\"].str.replace(\" \", \"\").astype(int)\n",
    "    df['term'] = df[\"term\"].str.replace(\"_def\", \"\")\n",
    "    df['term']= df[\"term\"].str.replace('[^a-zA-Z0-9]', '')\n",
    "    mask=df[\"term\"].str.isalpha()\n",
    "    df=df.loc[mask] \n",
    "    df['term'] = df['term'].str.upper()\n",
    "    \n",
    "    #df['archive'] = df[\"archive_filename\"].str.replace(\"/ \", \"\")144133901/\n",
    "    \n",
    "\n",
    "    list_editions={\"1\":[\"first\", \"First\"], \"2\":[\"second\", \"Second\"],\\\n",
    "               \"3\":[\"third\", \"Third\"],\\\n",
    "               \"4\":[\"fourth\", \"Fourth\"], \\\n",
    "               \"5\":[\"fifth\",\"Fifth\"], \"6\":[\"sixth\",\"Sixth\"],\\\n",
    "               \"7\":[\"seventh\", \"Seventh\"], \"8\":[\"eighth\", \"Eighth\"]} \n",
    "    \n",
    "    for ed in list_editions:\n",
    "        for ed_versions in list_editions[ed]:\n",
    "            mask = df[\"edition\"].str.contains(ed_versions)\n",
    "            df.loc[mask, 'edition_num'] = ed  \n",
    "    df['edition_num']=df[\"edition_num\"].astype(int)\n",
    "    a=df[\"archive_filename\"].str.split(\"/\").str[-2]\n",
    "    df['source_text_file']= a+ \"/\" + df[\"source_text_file\"]   \n",
    "    df= df.drop(['edition', 'archive_filename'], axis=1)\n",
    "    \n",
    "    \n",
    "    df = df[[\"term\", \"definition\", \"related_terms\", \"num_article_words\", \"header\", \"page_num\", \"term_id_in_page\", \"type_article\", \"edition_num\", \"volume\", \"letters\", \"year\", \"title\",  \"place\", \"source_text_file\"  ]]\n",
    "    \n",
    "    df = df[df['term'] != '']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_file(filename):\n",
    "    with open('./results_NLS/'+filename, 'r') as f:\n",
    "        query_results = safe_load(f)\n",
    "    \n",
    "    df = create_dataframe(query_results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_json(json_dict):\n",
    "    \"\"\"\n",
    "    Method that given a JSON object, removes all its empty fields.\n",
    "    This method simplifies the resultant JSON.\n",
    "    :param json_dict input JSON file to prune\n",
    "    :return JSON file removing empty values\n",
    "    \"\"\"\n",
    "    final_dict = {}\n",
    "    if not (isinstance(json_dict, dict)):\n",
    "        # Ensure the element provided is a dict\n",
    "        return json_dict\n",
    "    else:\n",
    "        for a, b in json_dict.items():\n",
    "            if b or isinstance(b, bool):\n",
    "                if isinstance(b, dict):\n",
    "                    aux_dict = prune_json(b)\n",
    "                    if aux_dict:  # Remove empty dicts\n",
    "                        final_dict[a] = aux_dict\n",
    "                elif isinstance(b, list):\n",
    "                    aux_list = list(filter(None, [prune_json(i) for i in b]))\n",
    "                    if len(aux_list) > 0:  # Remove empty lists\n",
    "                        final_dict[a] = aux_list\n",
    "                else:\n",
    "                    final_dict[a] = b\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_entries(query_results_updated, eliminate_pages):\n",
    "    new_results={}\n",
    "    for edition in query_results_updated:\n",
    "        new_results[edition]=[]\n",
    "        for page_idx in range(0, len(query_results_updated[edition])):\n",
    "            if page_idx not in eliminate_pages[edition]:\n",
    "                new_results[edition].append(query_results_updated[edition][page_idx])\n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_terms(query_results):\n",
    "    eliminate_pages={}\n",
    "    for edition in query_results:\n",
    "        eliminate_pages[edition]=[]\n",
    "        page_number_dict={}\n",
    "        for page_idx in range(0, len(query_results[edition])):\n",
    "            \n",
    "            current_page=query_results[edition][page_idx][0]\n",
    "            if current_page not in page_number_dict:\n",
    "                page_number_dict[current_page]=page_idx\n",
    "        \n",
    "            element = query_results[edition][page_idx][1]\n",
    "            if \"previous_page\" in element['term']:\n",
    "                current_definition= element[\"definition\"]\n",
    "                previous_page_idx= page_idx -1\n",
    "                previous_page_number = current_page -1\n",
    "                num_article_words=element[\"num_article_words\"]\n",
    "                related_terms=element[\"related_terms\"]\n",
    "                \n",
    "                \n",
    "                prev_elements = query_results[edition][previous_page_idx][1]\n",
    "                if prev_elements[\"last_term_in_page\"]:\n",
    "                   \n",
    "                    prev_elements[\"definition\"]+=current_definition\n",
    "                    prev_elements[\"num_article_words\"]+=num_article_words\n",
    "                    prev_elements[\"related_terms\"]+= related_terms\n",
    "                    prev_number = int(prev_elements['text_unit_id'].split(\"Page\")[1])\n",
    "                    \n",
    "                    for prev_articles_idx in range(page_number_dict[prev_number], page_idx):\n",
    "                       \n",
    "                        if query_results[edition][prev_articles_idx][0] == prev_number:\n",
    "                           \n",
    "                            query_results[edition][prev_articles_idx][1][\"num_page_words\"]+=num_article_words\n",
    "                    \n",
    "                  \n",
    "                    for update_element_idx in range(page_number_dict[current_page], page_idx+1):\n",
    "                        if query_results[edition][update_element_idx][0] == current_page:\n",
    "                            query_results[edition][update_element_idx][1][\"num_page_words\"]-=num_article_words\n",
    "                            query_results[edition][update_element_idx][1][\"num_articles\"]-=1\n",
    "                    \n",
    "                \n",
    "                eliminate_pages[edition].append(page_idx)\n",
    "              \n",
    "   \n",
    "    new_results= delete_entries(query_results, eliminate_pages)\n",
    "    \n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading, Merging articles,  and Writing the results in a new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to take the output of the defoe files, and we are going to merge the terms that splitted across pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results=read_query_results('results_eb_1_edition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results_updated =merge_terms(query_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been merged, we are going to store it in a file, just to have the data merged.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_results(\"results_eb_1_edition_updated\", query_results_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a dataframe from the updated results\n",
    "\n",
    "Once, we have the terms properly merged, we are going to create a dataframe, which we will be use later to do further exploration. In this dataframe we have dropped some information from the original defoe files, that we don not longer need. \n",
    "\n",
    "**The dataframe will have the following columns**\n",
    "\n",
    "- definition:           Definition of the article\n",
    "- edition_num:          1,2,3,4,5,6,7,8\n",
    "- header:               Header of the page's article                                  \n",
    "- num_article_words:    Number of words per article\n",
    "- place:                Place where the volume was edited (e.g. Edinburgh)                                    \n",
    "- related_terms:        Related articles (see X article)  \n",
    "- source_text_file:     File Path of the XML file from which the article belongs       \n",
    "- term:                 Article name                            \n",
    "- term_id_in_page:      Number of article in the page     \n",
    "- page_num:                 Page Number\n",
    "- title:               Title of the Volume\n",
    "- type_article:            Type of Page [Full Page| Topic| Mix | Articles]                                       \n",
    "- year:                 Year of the Volume\n",
    "- volume:               volume (e.g. 1)\n",
    "- letters:              leters of the volume (A-B)\n",
    "- edition_num:           1,2,3,4,5,6,7,8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=create_dataframe(query_results_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>definition</th>\n",
       "      <th>related_terms</th>\n",
       "      <th>num_article_words</th>\n",
       "      <th>header</th>\n",
       "      <th>page_num</th>\n",
       "      <th>term_id_in_page</th>\n",
       "      <th>type_article</th>\n",
       "      <th>edition_num</th>\n",
       "      <th>volume</th>\n",
       "      <th>letters</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>place</th>\n",
       "      <th>source_text_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29298</td>\n",
       "      <td>ZWEIBRUGGEN</td>\n",
       "      <td>a county of the palatinate of the Rhine, in Ge...</td>\n",
       "      <td>[SQALVS]</td>\n",
       "      <td>23</td>\n",
       "      <td>ZoDZYG</td>\n",
       "      <td>857</td>\n",
       "      <td>23</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>M-Z</td>\n",
       "      <td>1773</td>\n",
       "      <td>Encyclopaedia Britannica: or, A dictionary of ...</td>\n",
       "      <td>London</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18837502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29299</td>\n",
       "      <td>ZYGOMA</td>\n",
       "      <td>in anatomy. See Anatomy p. 152.</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>ZoDZYG</td>\n",
       "      <td>857</td>\n",
       "      <td>24</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>M-Z</td>\n",
       "      <td>1773</td>\n",
       "      <td>Encyclopaedia Britannica: or, A dictionary of ...</td>\n",
       "      <td>London</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18837502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29300</td>\n",
       "      <td>ZYGOMATICUS</td>\n",
       "      <td>in anatomy,. See Anatomy, p. 306,</td>\n",
       "      <td>[ANATOMY]</td>\n",
       "      <td>6</td>\n",
       "      <td>ZoDZYG</td>\n",
       "      <td>857</td>\n",
       "      <td>25</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>M-Z</td>\n",
       "      <td>1773</td>\n",
       "      <td>Encyclopaedia Britannica: or, A dictionary of ...</td>\n",
       "      <td>London</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18837502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29301</td>\n",
       "      <td>ZYGOPHYLLUM</td>\n",
       "      <td>in botany, a gr.nus of the decanoria monogyma ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>ZoDZYG</td>\n",
       "      <td>857</td>\n",
       "      <td>26</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>M-Z</td>\n",
       "      <td>1773</td>\n",
       "      <td>Encyclopaedia Britannica: or, A dictionary of ...</td>\n",
       "      <td>London</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18837502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29302</td>\n",
       "      <td>CORRIGENDA</td>\n",
       "      <td>page 132. col. I. !. 2J, 26. at frow the faliv...</td>\n",
       "      <td>[]</td>\n",
       "      <td>655</td>\n",
       "      <td>CORRIGENDA</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>M-Z</td>\n",
       "      <td>1773</td>\n",
       "      <td>Encyclopaedia Britannica: or, A dictionary of ...</td>\n",
       "      <td>London</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18837503...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term                                         definition  \\\n",
       "29298  ZWEIBRUGGEN  a county of the palatinate of the Rhine, in Ge...   \n",
       "29299       ZYGOMA                    in anatomy. See Anatomy p. 152.   \n",
       "29300  ZYGOMATICUS                  in anatomy,. See Anatomy, p. 306,   \n",
       "29301  ZYGOPHYLLUM  in botany, a gr.nus of the decanoria monogyma ...   \n",
       "29302   CORRIGENDA  page 132. col. I. !. 2J, 26. at frow the faliv...   \n",
       "\n",
       "      related_terms  num_article_words      header  page_num  term_id_in_page  \\\n",
       "29298      [SQALVS]                 23      ZoDZYG       857               23   \n",
       "29299            []                  6      ZoDZYG       857               24   \n",
       "29300     [ANATOMY]                  6      ZoDZYG       857               25   \n",
       "29301            []                 48      ZoDZYG       857               26   \n",
       "29302            []                655  CORRIGENDA       858                0   \n",
       "\n",
       "      type_article  edition_num  volume letters  year  \\\n",
       "29298      Article            1       3     M-Z  1773   \n",
       "29299      Article            1       3     M-Z  1773   \n",
       "29300      Article            1       3     M-Z  1773   \n",
       "29301      Article            1       3     M-Z  1773   \n",
       "29302        Topic            1       3     M-Z  1773   \n",
       "\n",
       "                                                   title   place  \\\n",
       "29298  Encyclopaedia Britannica: or, A dictionary of ...  London   \n",
       "29299  Encyclopaedia Britannica: or, A dictionary of ...  London   \n",
       "29300  Encyclopaedia Britannica: or, A dictionary of ...  London   \n",
       "29301  Encyclopaedia Britannica: or, A dictionary of ...  London   \n",
       "29302  Encyclopaedia Britannica: or, A dictionary of ...  London   \n",
       "\n",
       "                                        source_text_file  \n",
       "29298  nls-data-encyclopaediaBritannica/alto/18837502...  \n",
       "29299  nls-data-encyclopaediaBritannica/alto/18837502...  \n",
       "29300  nls-data-encyclopaediaBritannica/alto/18837502...  \n",
       "29301  nls-data-encyclopaediaBritannica/alto/18837502...  \n",
       "29302  nls-data-encyclopaediaBritannica/alto/18837503...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Saving the dataframe to json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(r'./results_NLS/results_eb_1_edition_postprocess_dataframe', orient=\"index\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
