{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging EB terms-  NLS -  Encyclopaedia Britannica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yaml import safe_load\n",
    "from pandas.io.json import json_normalize\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_query_results(filename):\n",
    "    with open('./results_NLS/'+filename, 'r') as f:\n",
    "        query_results = safe_load(f)\n",
    "    return query_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_results(filename, results):\n",
    "    with open('./results_NLS/'+filename, 'w') as f:\n",
    "        documents = yaml.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(query_results):\n",
    "  \n",
    "    \n",
    "    for edition in query_results:\n",
    "        for page in query_results[edition]:\n",
    "            #print(page[1].keys())\n",
    "            column_list=list(page[1].keys())\n",
    "            break\n",
    "        break\n",
    "        \n",
    "    data=[]\n",
    "    for edition in query_results:\n",
    "        for page in query_results[edition]:\n",
    "            try:\n",
    "                data.append(page[1])\n",
    "               \n",
    "            except:\n",
    "                pass\n",
    "    df = pd.DataFrame(data, columns = column_list)\n",
    "    #removing the columns that I dont need \n",
    "    df= df.drop(['last_term_in_page', 'model', 'num_articles', 'num_page_words', 'num_text_unit' , 'text_unit', 'type_archive'], axis=1)\n",
    "    #renaming the page num\n",
    "    df= df.rename(columns={\"text_unit_id\": \"start_page\", \"type_page\": \"type_article\"})\n",
    "    #removing 'Page' from the string\n",
    "    df[\"start_page\"] = df[\"start_page\"].str.replace(\"Page\", \"\")\n",
    "    df[\"start_page\"] = df[\"start_page\"].astype(int)\n",
    "    df[\"end_page\"] = df[\"end_page\"].astype(int)\n",
    "    df_tmp= df[\"edition\"].str.split(\"Volume\", expand=True)[1].str.split(\",\", expand=True)\n",
    "    df[\"volume\"]= df_tmp[0]\n",
    "    df[\"letters\"] = df_tmp[1]\n",
    "    df['volume'] = df[\"volume\"].str.replace(\" \", \"\").astype(int)\n",
    "    df['term'] = df[\"term\"].str.replace(\"_def\", \"\")\n",
    "    df['term']= df[\"term\"].str.replace('[^a-zA-Z0-9]', '')\n",
    "    mask=df[\"term\"].str.isalpha()\n",
    "    df=df.loc[mask] \n",
    "    df['term'] = df['term'].str.upper()\n",
    "    \n",
    "    #df['archive'] = df[\"archive_filename\"].str.replace(\"/ \", \"\")144133901/\n",
    "    \n",
    "\n",
    "    list_editions={\"1\":[\"first\", \"First\"], \"2\":[\"second\", \"Second\"],\\\n",
    "               \"3\":[\"third\", \"Third\"],\\\n",
    "               \"4\":[\"fourth\", \"Fourth\"], \\\n",
    "               \"5\":[\"fifth\",\"Fifth\"], \"6\":[\"sixth\",\"Sixth\"],\\\n",
    "               \"7\":[\"seventh\", \"Seventh\"], \"8\":[\"eighth\", \"Eighth\"]} \n",
    "    \n",
    "    for ed in list_editions:\n",
    "        for ed_versions in list_editions[ed]:\n",
    "            mask = df[\"edition\"].str.contains(ed_versions)\n",
    "            df.loc[mask, 'edition_num'] = ed  \n",
    "    df['edition_num']=df[\"edition_num\"].astype(int)\n",
    "    a=df[\"archive_filename\"].str.split(\"/\").str[-2]\n",
    "    df['source_text_file']= a+ \"/\" + df[\"source_text_file\"]   \n",
    "    df= df.drop(['edition', 'archive_filename'], axis=1)\n",
    "    \n",
    "    \n",
    "    df = df[[\"term\", \"definition\", \"related_terms\", \"num_article_words\", \"header\", \"start_page\", \"end_page\",  \"term_id_in_page\", \"type_article\", \"edition_num\", \"volume\", \"letters\", \"year\", \"title\",  \"place\", \"source_text_file\"  ]]\n",
    "    \n",
    "    df = df[df['term'] != '']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    a=a.lower()\n",
    "    b=b.lower()\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_file(filename):\n",
    "    with open('./results_NLS/'+filename, 'r') as f:\n",
    "        query_results = safe_load(f)\n",
    "    \n",
    "    df = create_dataframe(query_results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_json(json_dict):\n",
    "    \"\"\"\n",
    "    Method that given a JSON object, removes all its empty fields.\n",
    "    This method simplifies the resultant JSON.\n",
    "    :param json_dict input JSON file to prune\n",
    "    :return JSON file removing empty values\n",
    "    \"\"\"\n",
    "    final_dict = {}\n",
    "    if not (isinstance(json_dict, dict)):\n",
    "        # Ensure the element provided is a dict\n",
    "        return json_dict\n",
    "    else:\n",
    "        for a, b in json_dict.items():\n",
    "            if b or isinstance(b, bool):\n",
    "                if isinstance(b, dict):\n",
    "                    aux_dict = prune_json(b)\n",
    "                    if aux_dict:  # Remove empty dicts\n",
    "                        final_dict[a] = aux_dict\n",
    "                elif isinstance(b, list):\n",
    "                    aux_list = list(filter(None, [prune_json(i) for i in b]))\n",
    "                    if len(aux_list) > 0:  # Remove empty lists\n",
    "                        final_dict[a] = aux_list\n",
    "                else:\n",
    "                    final_dict[a] = b\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_entries(query_results_updated, eliminate_pages):\n",
    "    new_results={}\n",
    "    for edition in query_results_updated:\n",
    "        new_results[edition]=[]\n",
    "        for page_idx in range(0, len(query_results_updated[edition])):\n",
    "            if page_idx not in eliminate_pages[edition]:\n",
    "                new_results[edition].append(query_results_updated[edition][page_idx])\n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_articles(query_results):\n",
    "    eliminate_pages={}\n",
    "    for edition in query_results:\n",
    "        eliminate_pages[edition]=[]\n",
    "        page_number_dict={}\n",
    "        for page_idx in range(0, len(query_results[edition])):\n",
    "            \n",
    "            current_page=query_results[edition][page_idx][0]\n",
    "            if current_page not in page_number_dict:\n",
    "                page_number_dict[current_page]=page_idx\n",
    "            \n",
    "            element = query_results[edition][page_idx][1]\n",
    "            if \"previous_page\" in element['term']:\n",
    "                current_definition= element[\"definition\"]\n",
    "                previous_page_idx= page_idx -1\n",
    "                previous_page_number = current_page -1\n",
    "                num_article_words=element[\"num_article_words\"]\n",
    "                related_terms=element[\"related_terms\"]\n",
    "            \n",
    "                \n",
    "                prev_elements = query_results[edition][previous_page_idx][1]\n",
    "                if prev_elements[\"last_term_in_page\"]:\n",
    "                   \n",
    "                    prev_elements[\"definition\"]+=current_definition\n",
    "                    prev_elements[\"num_article_words\"]+=num_article_words\n",
    "                    prev_elements[\"related_terms\"]+= related_terms\n",
    "                    prev_number = int(prev_elements['text_unit_id'].split(\"Page\")[1])\n",
    "                    prev_elements[\"end_page\"] = current_page\n",
    "                    \n",
    "                    for prev_articles_idx in range(page_number_dict[prev_number], page_idx):\n",
    "                       \n",
    "                        if query_results[edition][prev_articles_idx][0] == prev_number:\n",
    "                           \n",
    "                            query_results[edition][prev_articles_idx][1][\"num_page_words\"]+=num_article_words\n",
    "                    \n",
    "                  \n",
    "                    for update_element_idx in range(page_number_dict[current_page], page_idx+1):\n",
    "                        if query_results[edition][update_element_idx][0] == current_page:\n",
    "                            query_results[edition][update_element_idx][1][\"num_page_words\"]-=num_article_words\n",
    "                            query_results[edition][update_element_idx][1][\"num_articles\"]-=1\n",
    "                    \n",
    "                \n",
    "                eliminate_pages[edition].append(page_idx)\n",
    "            else:\n",
    "                element[\"end_page\"] = current_page  \n",
    "   \n",
    "    new_results= delete_entries(query_results, eliminate_pages)\n",
    "    \n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_topics(query_results):\n",
    "    eliminate_pages={}\n",
    "    provenance_removal={}\n",
    "    for edition in query_results:\n",
    "        eliminate_pages[edition]=[]\n",
    "        provenance_removal[edition]=[]\n",
    "        merged_topics={}\n",
    "        page_idx = 0\n",
    "        while page_idx < len(query_results[edition]):\n",
    "            current_page=query_results[edition][page_idx][0]        \n",
    "            element = query_results[edition][page_idx][1]\n",
    "\n",
    "            if \"Topic\" in element['type_page']:\n",
    "                term= element[\"term\"]\n",
    "                next_page_idx= page_idx + 1\n",
    "                       \n",
    "                if next_page_idx < len(query_results[edition]):\n",
    "                    flag=0\n",
    "                    for p_id in range(next_page_idx, len(query_results[edition])):\n",
    "                        next_element = query_results[edition][p_id][1]\n",
    "                      \n",
    "                        if similar(term, next_element[\"term\"]) > 0.72:\n",
    "            \n",
    "                            if term not in merged_topics:\n",
    "                                merged_topics[term]=[]\n",
    "                            merged_topics[term].append(next_element[\"term\"])\n",
    "                            \n",
    "                            element[\"definition\"]+=next_element[\"definition\"]\n",
    "                            element[\"num_article_words\"]+=next_element[\"num_article_words\"]\n",
    "                            element[\"num_page_words\"]+=next_element[\"num_page_words\"]                  \n",
    "                            element[\"related_terms\"]+= next_element[\"related_terms\"]\n",
    "                            element[\"end_page\"] = int(next_element['text_unit_id'].split(\"Page\")[1])\n",
    "                            provenance_removal[edition].append(element[\"end_page\"])\n",
    "\n",
    "                            eliminate_pages[edition].append(p_id)\n",
    "                     \n",
    "                        else:\n",
    "                            break\n",
    "                    page_idx= p_id \n",
    "                    \n",
    "                else:\n",
    "                    page_idx = next_page_idx\n",
    "               \n",
    "            else:\n",
    "                page_idx += 1\n",
    "           \n",
    "    for ed in provenance_removal:\n",
    "        print(\"ED:%s -- removing the following pages %s\" %(ed, provenance_removal[ed]))\n",
    "    new_results= delete_entries(query_results, eliminate_pages)\n",
    "    \n",
    "    return new_results, merged_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading, Merging articles,  and Writing the results in a new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to take the output of the defoe files, and we are going to merge the terms that splitted across pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results=read_query_results('results_eb_1_edition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets mege articles splitted across pages together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results_articles =merge_articles(query_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets merge topics together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED:First edition, 1771, Volume 1, A-B -- removing the following pages [14, 62, 65, 66, 71, 72, 73, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 99, 115, 119, 120, 121, 122, 123, 124, 137, 138, 141, 142, 143, 146, 150, 155, 200, 201, 208, 209, 232, 235, 244, 245, 253, 254, 256, 257, 261, 270, 271, 302, 303, 309, 328, 329, 370, 373, 402, 403, 404, 406, 420, 421, 422, 439, 440, 442, 443, 451, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 475, 483, 484, 487, 488, 494, 495, 496, 498, 499, 500, 501, 505, 520, 521, 522, 523, 524, 525, 526, 527, 528, 531, 532, 533, 534, 535, 536, 537, 538, 541, 544, 547, 548, 549, 554, 555, 556, 557, 558, 559, 560, 563, 564, 565, 566, 569, 570, 571, 572, 575, 576, 577, 578, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 594, 595, 596, 601, 602, 603, 604, 671, 674, 675, 678, 679, 680, 694, 703, 707, 708, 709, 710, 711, 712, 713, 739, 749, 750, 751, 752, 756, 757, 758, 759, 760, 761, 765, 766, 778, 779, 780, 781, 782, 783, 785, 799, 800, 802, 803, 805]\n",
      "ED:First edition, 1771, Volume 2, C-L -- removing the following pages [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 114, 115, 116, 117, 118, 119, 122, 123, 124, 125, 128, 129, 130, 131, 132, 133, 134, 135, 136, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 181, 183, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 259, 260, 261, 262, 265, 266, 267, 268, 298, 301, 302, 416, 417, 420, 421, 422, 425, 426, 427, 496, 497, 498, 499, 500, 501, 502, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 524, 525, 526, 527, 528, 529, 568, 581, 582, 587, 588, 589, 590, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 629, 630, 631, 632, 633, 634, 635, 645, 646, 647, 648, 649, 664, 668, 669, 675, 680, 681, 682, 685, 686, 687, 688, 694, 695, 696, 699, 700, 722, 723, 727, 732, 733, 734, 735, 736, 737, 756, 787, 788, 789, 792, 793, 800, 801, 802, 805, 806, 807, 808, 809, 810, 811, 812, 815, 816, 817, 818, 819, 900, 901, 906, 907, 908, 909, 914, 915, 916, 917, 919, 920, 921, 924, 925, 926, 929, 938, 939, 941, 942, 958, 962, 992, 993, 996, 997, 999, 1001, 1002, 1003, 1004, 1009]\n",
      "ED:First edition, 1771, Volume 3, M-Z -- removing the following pages [46, 47, 48, 49, 54, 55, 56, 59, 60, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 82, 83, 84, 85, 86, 89, 90, 91, 94, 96, 97, 98, 99, 100, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 180, 181, 182, 183, 186, 187, 189, 190, 201, 202, 203, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 228, 229, 230, 231, 232, 233, 234, 235, 241, 242, 243, 246, 247, 248, 251, 254, 255, 256, 259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 312, 313, 316, 317, 318, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 351, 366, 367, 368, 369, 370, 371, 372, 374, 376, 377, 378, 384, 385, 386, 387, 388, 389, 390, 391, 392, 424, 427, 428, 429, 431, 434, 436, 444, 445, 456, 457, 484, 492, 493, 507, 549, 550, 555, 568, 569, 570, 571, 572, 573, 574, 579, 580, 584, 585, 586, 587, 625, 626, 630, 631, 632, 633, 634, 680, 681, 682, 683, 684, 692, 693, 694, 695, 696, 749, 750, 751, 753, 758, 760, 764, 765, 766, 767, 770, 771, 774, 775, 778, 784, 789, 796, 818, 822]\n",
      "ED:First edition, 1773, Volume 1, A-B -- removing the following pages [12, 13, 14, 64, 67, 68, 73, 74, 75, 76, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 101, 102, 121, 122, 126, 127, 128, 129, 130, 140, 141, 142, 143, 144, 145, 151, 152, 157, 185, 186, 193, 194, 198, 199, 205, 207, 216, 217, 251, 252, 253, 254, 256, 257, 258, 259, 264, 277, 281, 318, 319, 329, 376, 377, 378, 379, 408, 409, 410, 415, 416, 426, 429, 430, 435, 436, 439, 440, 449, 455, 460, 461, 465, 467, 471, 472, 473, 489, 490, 493, 500, 501, 503, 505, 506, 507, 508, 510, 511, 526, 527, 528, 529, 530, 531, 532, 533, 534, 538, 539, 540, 543, 544, 547, 548, 549, 550, 551, 552, 555, 556, 557, 558, 559, 560, 561, 562, 563, 566, 569, 570, 571, 572, 575, 576, 579, 580, 583, 584, 585, 586, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 608, 611, 612, 679, 680, 681, 682, 683, 684, 685, 686, 687, 699, 700, 711, 713, 714, 716, 717, 718, 719, 725, 728, 729, 730, 757, 758, 759, 760, 761, 762, 766, 769, 770, 773, 774, 779, 783, 785, 786, 787, 789, 790, 791, 792, 793, 807, 808, 809, 810, 811, 813]\n",
      "ED:First edition, 1773, Volume 2, C-L -- removing the following pages [90, 92, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 116, 117, 120, 121, 123, 124, 125, 126, 133, 136, 137, 138, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 159, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 189, 191, 192, 193, 194, 197, 198, 199, 200, 201, 204, 205, 206, 265, 266, 267, 268, 269, 270, 271, 272, 274, 304, 307, 308, 432, 433, 436, 437, 504, 505, 506, 508, 509, 510, 511, 516, 517, 518, 519, 524, 525, 526, 529, 534, 535, 536, 540, 579, 589, 590, 597, 621, 623, 626, 627, 630, 631, 632, 636, 637, 638, 643, 654, 657, 680, 688, 689, 690, 693, 694, 695, 696, 697, 700, 703, 704, 705, 706, 733, 741, 800, 801, 802, 803, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 825, 826, 829, 830, 831, 898, 899, 900, 901, 902, 903, 904, 910, 911, 918, 923, 934, 945, 946, 947, 960, 965, 970, 971, 972, 1002, 1004, 1005, 1006, 1013, 1014, 1019]\n",
      "ED:First edition, 1773, Volume 3, M-Z -- removing the following pages [44, 45, 46, 47, 48, 51, 52, 55, 56, 57, 58, 59, 65, 66, 69, 72, 73, 74, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 101, 102, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 184, 185, 186, 187, 188, 189, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 231, 232, 233, 236, 237, 238, 241, 242, 243, 244, 245, 246, 249, 250, 251, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 302, 303, 304, 305, 306, 307, 308, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 329, 330, 331, 332, 333, 334, 335, 353, 355, 356, 357, 358, 359, 360, 361, 366, 370, 375, 376, 378, 379, 380, 382, 383, 384, 419, 420, 424, 425, 429, 430, 431, 446, 474, 475, 476, 477, 491, 492, 493, 537, 538, 558, 559, 562, 563, 564, 576, 577, 616, 617, 618, 619, 620, 670, 671, 672, 673, 674, 682, 683, 684, 685, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 779, 786, 811, 812, 838]\n"
     ]
    }
   ],
   "source": [
    "query_results_updated, merged_topics =merge_topics(query_results_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list of merged topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MECHANICS': ['MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'AMECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECIIANICS',\n",
       "  'oMECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'MECHANICS',\n",
       "  'SMECHANICS'],\n",
       " 'MEDICINE': ['MEDCINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEIICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDCINE',\n",
       "  'jMEDICINE',\n",
       "  'MEDCINE',\n",
       "  'MEDCINE',\n",
       "  'MEDCINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDIcINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'looMEDICINE',\n",
       "  'MEDCINE',\n",
       "  'ioMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'jcMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'JMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'noMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'iiMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'iiMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'jMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDIClNE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'VyMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'iMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'IgMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'iMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'ioMEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'joMEDIClNE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDIClNE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'mCINE',\n",
       "  'MEDICINE'],\n",
       " 'SoMEDCINE': ['MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'MEDICINE',\n",
       "  'pdMEDICINE'],\n",
       " 'METAPIYSICS': ['IMETAPIYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'iSoMETAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPEYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPElYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPIYSICS',\n",
       "  'METAPaysics',\n",
       "  'IMETAPIIYSICS',\n",
       "  'METAPIYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSIC',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS',\n",
       "  'METAPHYSICS'],\n",
       " 'tkMIDWIFERY': ['MIDWIFERY', 'MIDWIFERY', 'MIDWIFERY'],\n",
       " 'MIDWIFERY': ['MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERV',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIPERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY'],\n",
       " 'MIDWIFER': ['MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERV',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFERY',\n",
       "  'MIDWIFEItY',\n",
       "  'MIDwFERY',\n",
       "  'MIDWIFEItY',\n",
       "  'MIDWIFERY'],\n",
       " 'MORALPHILOSOPHY': ['MORALPHILOSOPHy',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHLOSOPHY',\n",
       "  'MORALPHILOSOPIIY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'sBomonalphILOSOPIIY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPIIY',\n",
       "  'MORALPHLOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'oMORALPHILOSGPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPKY',\n",
       "  'MORALPHLOSOPHY',\n",
       "  'MOIIALPHILOSOPIIY',\n",
       "  'MORALPHILOSPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'goMORALPIIILOSOPIIY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'MORALPHILOSOPHY',\n",
       "  'oMORALPHILOOPHY',\n",
       "  'MORALPHILOSOPHy'],\n",
       " 'giMUSICK': ['usIcK',\n",
       "  'MUSICK',\n",
       "  'JMUSICK',\n",
       "  'MUSICK',\n",
       "  'MUSICK',\n",
       "  'MUSICK',\n",
       "  'gMUSICK',\n",
       "  'MUSICK'],\n",
       " 'MUSICK': ['MUSICK',\n",
       "  'MUSIGK',\n",
       "  'MUSICK',\n",
       "  'MUSIGK',\n",
       "  'MUSICK',\n",
       "  'MUSICE',\n",
       "  'MUSICK',\n",
       "  'MUSIcK',\n",
       "  'MUICK'],\n",
       " 'SMUSICK': ['MUSICK'],\n",
       " 'NAVIGATION': ['NAVIGATION',\n",
       "  'NAVIGATION',\n",
       "  'NAVIGATION',\n",
       "  'NAVIGI',\n",
       "  'NAVIGATION'],\n",
       " 'AVIGATION': ['NAVIGATION', 'SoNAVIGATION', 'iNAVIGATION'],\n",
       " 'OPTICS': ['OPTICs', 'OPTICS', 'OPTIcs', 'OPTICS'],\n",
       " 'OPTIcs': ['OPTICS', 'OPTIcs', 'OPTIcS'],\n",
       " 'PERSPECTIVE': ['PEHSPECTIVF', 'PEUSPECTIVE'],\n",
       " 'PNEUMATICS': ['FNETJMATICS', 'PNEUMATICS', 'coPNEUMATICS', 'PNEUMATICS'],\n",
       " 'PNEUMATiCS': ['PNEUMATICS', 'FNEUMATICS', 'PNEUMATIS'],\n",
       " 'RELIGIONorTHEOLOGY': ['RELIGIONorTHEOLOGY',\n",
       "  'RELIGIONorTHEOLOGY',\n",
       "  'RELIGIONoTHEOLOGY',\n",
       "  'RELIGIONorTHEOLOGY',\n",
       "  'RELGIONorTHEOLOGY'],\n",
       " 'SHRTHANDWRITING': ['jSHORTHANDWRITING',\n",
       "  'SHORTHANDWRITING',\n",
       "  'SHORTHANTWRITING',\n",
       "  'SHORTHANWRITING',\n",
       "  'SHORTHANDWRITING'],\n",
       " 'shorthandWRITING': ['SHORTHANDWRITING',\n",
       "  'SHORTHANDWRITING',\n",
       "  'SHORTHANDWRITING',\n",
       "  'SHOUTHANDWRITING'],\n",
       " 'SURGERY': ['StrRGERY',\n",
       "  'SURGEIIY',\n",
       "  'SURGERY',\n",
       "  'oSURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SUKGERY',\n",
       "  'sunGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'ISURGERY',\n",
       "  'SURGEY',\n",
       "  'SURERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURIERY',\n",
       "  'SURGRY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'roSURGERY',\n",
       "  'SURGERY',\n",
       "  'SURCrERY',\n",
       "  'SURCERY',\n",
       "  'SUGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY',\n",
       "  'SURGERY'],\n",
       " 'TANNING': ['tuTANNING'],\n",
       " 'froTRICONOMETRY': ['TRIGONOMETRY', 'TRIGONOMETRY'],\n",
       " 'WATCHandCLOCKWORK': ['lWATCHandLOCKWORK']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been merged, we are going to store it in a file, just to have the data merged.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_results(\"results_eb_1_edition_updated\", query_results_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a dataframe from the updated results\n",
    "\n",
    "Once, we have the terms properly merged, we are going to create a dataframe, which we will be use later to do further exploration. In this dataframe we have dropped some information from the original defoe files, that we don not longer need. \n",
    "\n",
    "**The dataframe will have the following columns**\n",
    "\n",
    "- definition:           Definition of the article\n",
    "- edition_num:          1,2,3,4,5,6,7,8\n",
    "- header:               Header of the page's article                                  \n",
    "- num_article_words:    Number of words per article\n",
    "- place:                Place where the volume was edited (e.g. Edinburgh)                                    \n",
    "- related_terms:        Related articles (see X article)  \n",
    "- source_text_file:     File Path of the XML file from which the article belongs       \n",
    "- term:                 Article name                            \n",
    "- term_id_in_page:      Number of article in the page     \n",
    "- start_page:           Number page in which the article starts \n",
    "- end_page:             Number page in which the article ends \n",
    "- title:               Title of the Volume\n",
    "- type_article:            Type of Page [Full Page| Topic| Mix | Articles]                                       \n",
    "- year:                 Year of the Volume\n",
    "- volume:               volume (e.g. 1)\n",
    "- letters:              leters of the volume (A-B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT DECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to filter OUT all the entries which are not Articles, Topics, or Mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=create_dataframe(query_results_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "includeKeywords=[\"Article\", \"Topic\", \"Mix\"]\n",
    "df=df[df[\"type_article\"].str.contains('|'.join(includeKeywords)).any(level=0)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>term</th>\n",
       "      <th>definition</th>\n",
       "      <th>related_terms</th>\n",
       "      <th>num_article_words</th>\n",
       "      <th>header</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>term_id_in_page</th>\n",
       "      <th>type_article</th>\n",
       "      <th>edition_num</th>\n",
       "      <th>volume</th>\n",
       "      <th>letters</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>place</th>\n",
       "      <th>source_text_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FIRSTARTICLE</td>\n",
       "      <td>S :u -I &gt;;J .1 M U a C V'</td>\n",
       "      <td>[]</td>\n",
       "      <td>10</td>\n",
       "      <td>**■*</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-B</td>\n",
       "      <td>1771</td>\n",
       "      <td>Encyclopaedia Britannica; or, A dictionary of ...</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18808281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>VIPREFACE</td>\n",
       "      <td>TH E Editors, though fully fen&amp;ble of the prop...</td>\n",
       "      <td>[]</td>\n",
       "      <td>410</td>\n",
       "      <td>viPREFACE</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-B</td>\n",
       "      <td>1771</td>\n",
       "      <td>Encyclopaedia Britannica; or, A dictionary of ...</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18808286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>LISTOFAUTHORSC</td>\n",
       "      <td>Albini tabule anatomies, Alfton’s ‘Tirocinium ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>911</td>\n",
       "      <td>LISTofAUTHORSc</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-B</td>\n",
       "      <td>1771</td>\n",
       "      <td>Encyclopaedia Britannica; or, A dictionary of ...</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18808287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>OR</td>\n",
       "      <td>A NEW A D I C T I A A, the name of several riv...</td>\n",
       "      <td>[]</td>\n",
       "      <td>54</td>\n",
       "      <td>EncyclopaediaBritannica</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-B</td>\n",
       "      <td>1771</td>\n",
       "      <td>Encyclopaedia Britannica; or, A dictionary of ...</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18808290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>AABAM</td>\n",
       "      <td>a term, among alchemifts, for lead,</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>EncyclopaediaBritannica</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-B</td>\n",
       "      <td>1771</td>\n",
       "      <td>Encyclopaedia Britannica; or, A dictionary of ...</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>nls-data-encyclopaediaBritannica/alto/18808290...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            term                                         definition  \\\n",
       "0      1    FIRSTARTICLE                          S :u -I >;J .1 M U a C V'   \n",
       "1      4       VIPREFACE  TH E Editors, though fully fen&ble of the prop...   \n",
       "2      5  LISTOFAUTHORSC  Albini tabule anatomies, Alfton’s ‘Tirocinium ...   \n",
       "3      6              OR  A NEW A D I C T I A A, the name of several riv...   \n",
       "4      7           AABAM                a term, among alchemifts, for lead,   \n",
       "\n",
       "  related_terms  num_article_words                   header  start_page  \\\n",
       "0            []                 10                    **■*            8   \n",
       "1            []                410                viPREFACE          12   \n",
       "2            []                911           LISTofAUTHORSc          13   \n",
       "3            []                 54  EncyclopaediaBritannica          15   \n",
       "4            []                  6  EncyclopaediaBritannica          15   \n",
       "\n",
       "   end_page  term_id_in_page type_article  edition_num  volume letters  year  \\\n",
       "0         8                0      Article            1       1     A-B  1771   \n",
       "1        12                0        Topic            1       1     A-B  1771   \n",
       "2        14                0        Topic            1       1     A-B  1771   \n",
       "3        15                0      Article            1       1     A-B  1771   \n",
       "4        15                1      Article            1       1     A-B  1771   \n",
       "\n",
       "                                               title      place  \\\n",
       "0  Encyclopaedia Britannica; or, A dictionary of ...  Edinburgh   \n",
       "1  Encyclopaedia Britannica; or, A dictionary of ...  Edinburgh   \n",
       "2  Encyclopaedia Britannica; or, A dictionary of ...  Edinburgh   \n",
       "3  Encyclopaedia Britannica; or, A dictionary of ...  Edinburgh   \n",
       "4  Encyclopaedia Britannica; or, A dictionary of ...  Edinburgh   \n",
       "\n",
       "                                    source_text_file  \n",
       "0  nls-data-encyclopaediaBritannica/alto/18808281...  \n",
       "1  nls-data-encyclopaediaBritannica/alto/18808286...  \n",
       "2  nls-data-encyclopaediaBritannica/alto/18808287...  \n",
       "3  nls-data-encyclopaediaBritannica/alto/18808290...  \n",
       "4  nls-data-encyclopaediaBritannica/alto/18808290...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Saving the dataframe to json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(r'./results_NLS/results_eb_1_edition_postprocess_dataframe', orient=\"index\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
