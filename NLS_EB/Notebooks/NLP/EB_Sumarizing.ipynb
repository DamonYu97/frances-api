{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Terms in the Encyclopaedia Britannica\n",
    "\n",
    "## Summarize text - Gensim - BERT- GPT2\n",
    "\n",
    "In this notebook we are going to do summarize the text of terms definitions with the dataframe that we have obtained either with the posprocess_eb.py script or Merging_EB_Terms.ipynb notebooks. Both methods obtain the same dataframe. \n",
    "\n",
    "We have selected the first Edition for this explorations, but we can run this notebook with any of the other editions.\n",
    "\n",
    "**Remark**: Edition 1, has 3 volumes, and it was printed twice, in 1771 and 1773. \n",
    "\n",
    "These methods rely on extracting several parts, such as phrases and sentences, from a piece of text and stack them together to create a summary. Therefore, identifying the right sentences for summarization is of utmost importance in an extractive method.\n",
    "\n",
    "- **Extractive Summarization**: These methods rely on extracting several parts, such as phrases and sentences, from a piece of text and stack them together to create a summary. Therefore, identifying the right sentences for summarization is of utmost importance in an extractive method.\n",
    "\n",
    "- **Abstractive Summarization**: These methods use advanced NLP techniques to generate an entirely new summary. Some parts of this summary may not even appear in the original text.\n",
    " \n",
    "Here we are going to focus on **extractive summarization technique**, using two libraries:\n",
    "- Gensim\n",
    "- Spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yaml import safe_load\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer, TransformerSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have dataframe with these columns\n",
    "\n",
    "- definition:           Definition of a term\n",
    "- editionNum:           1,2,3,4,5,6,7,8\n",
    "- editionTitle:         Title of the edition\n",
    "- header:               Header of the page's term                                  \n",
    "- place:                Place where the volume was edited (e.g. Edinburgh)                                    \n",
    "- relatedTerms:         Related terms (see X article)  \n",
    "- altoXML:              File Path of the XML file from which the term belongs       \n",
    "- term:                 Term name                            \n",
    "- positionPage:         Position of ther term in the page     \n",
    "- startsAt:             Number page in which the term definition starts \n",
    "- endsAt:               Number page in which the term definition ends \n",
    "- volumeTitle:          Title of the Volume\n",
    "- typeTerm:             Type of term [Topic| Articles]                                       \n",
    "- year:                 Year of the edition\n",
    "- volumeNum:            Volume number (e.g. 1)\n",
    "- letters:              leters of the volume (A-B)\n",
    "- part:                 Part of the volume (e.g 1)\n",
    "- supplement:           Supplement's Title\n",
    "- supplementsTo:        It suppelements to editions [1, 2, 3....]\n",
    "- numberOfWords:        Number of words per term definition\n",
    "- numberOfTerms:        Number of terms per page\n",
    "- numberOfPages:        Number of pages per volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataframe from JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testing with Spacy\n",
    "\n",
    "Following https://medium.com/analytics-vidhya/text-summarization-using-spacy-ca4867c6b744 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical model of sample data, known as “training data”, in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning and focuses on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics.\"\n",
    "doc=create_document(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Filtering tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword =[]\n",
    "stopwords = list(STOP_WORDS)\n",
    "pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "for token in doc:\n",
    "    if (token.text in stopwords or token.text in punctuation):\n",
    "        continue\n",
    "    if (token.pos_ in pos_tag):\n",
    "        keyword.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('learning', 8), ('Machine', 4), ('study', 3), ('algorithms', 3), ('task', 3)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_word = Counter(keyword)\n",
    "freq_word.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Machine', 'learning', 'ML', 'scientific', 'study', 'algorithms', 'statistical', 'models', 'computer', 'systems', 'use', 'improve', 'performance', 'specific', 'task', 'build', 'mathematical', 'model', 'sample', 'data', 'known', 'training', 'order', 'predictions', 'decisions', 'programmed', 'perform', 'applications', 'email', 'filtering', 'detection', 'network', 'intruders', 'vision', 'infeasible', 'develop', 'algorithm', 'instructions', 'performing', 'related', 'computational', 'statistics', 'focuses', 'making', 'computers', 'optimization', 'delivers', 'methods', 'theory', 'application', 'domains', 'field', 'machine', 'Data', 'mining', 'exploratory', 'analysis', 'unsupervised', 'business', 'problems', 'referred', 'predictive', 'analytics'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('learning', 0.125),\n ('Machine', 0.0625),\n ('study', 0.046875),\n ('algorithms', 0.046875),\n ('task', 0.046875)]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_freq = Counter(keyword).most_common(1)[0][1]\n",
    "print(freq_word.keys())\n",
    "for word in freq_word.keys():\n",
    "    freq_word[word] = (freq_word[word]/max_freq)\n",
    "freq_word.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Weighing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_strength={}\n",
    "for sent in doc.sents:\n",
    "    for word in sent:\n",
    "        if word.text in freq_word.keys():\n",
    "            if sent in sent_strength.keys():\n",
    "                sent_strength[sent]+=freq_word[word.text]\n",
    "            else:\n",
    "                sent_strength[sent] = freq_word[word.text]\n",
    "#print(sent_strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Summarizing the string\n",
    "\n",
    "And the nlargest function returns a list containing the top 3 sentences which are stored as summarized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_sentences = nlargest(3, sent_strength, key=sent_strength.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning algorithms build a mathematical model of sample data, known as “training data”, in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Data mining is a field of study within machine learning and focuses on exploratory data analysis through unsupervised learning.\n"
     ]
    }
   ],
   "source": [
    "final_sentences = [w.text for w in summarized_sentences]\n",
    "summary =' '.join(final_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "550"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ly40/Documents/frances-ai/env/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer()\n",
    "result = model(text, min_length=60)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Data mining is a field of study within machine learning and focuses on exploratory data analysis through unsupervised learning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ly40/Documents/frances-ai/env/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
    "full = ''.join(GPT2_model(text, min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ly40/Documents/frances-ai/env/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full = ''.join(model(text, min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim_sum_ext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summarizer\n\u001B[1;32m      2\u001B[0m summarizer(doc)\n",
      "File \u001B[0;32m~/Documents/frances-ai/env/lib/python3.9/site-packages/gensim_sum_ext/summarizer.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycorenlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StanfordCoreNLP\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummarization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpagerank_weighted\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pagerank_weighted \u001B[38;5;28;01mas\u001B[39;00m _pagerank\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummarization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommons\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_graph \u001B[38;5;28;01mas\u001B[39;00m _build_graph\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummarization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommons\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m remove_unreachable_nodes \u001B[38;5;28;01mas\u001B[39;00m _remove_unreachable_nodes\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
